{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T6 - Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/tut_calibration.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Ftut_calibration.ipynb).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disease models typically require contextualization to a relevant setting of interest prior to addressing \"what-if\" scenario questions. The process of tuning model input parameters so that model outputs match observed data is known as calibration. There are many approaches to model calibration, ranging from manual tuning to fully Bayesian methods.\n",
    "\n",
    "For many applications, we have found that an optimization-based approach is sufficient. Such methods avoid the tedious process of manual tuning and are less computationally expensive than fully Bayesian methods. One such optimization-based approach is the Optuna library, which is a Bayesian hyperparameter optimization framework. Optuna is designed for tuning hyperparameters of machine learning models, but it can also be used to calibrate disease models.\n",
    "\n",
    "Calibration libraries often treat the disease model as a black box, where the input parameters are the \"hyperparameters\" to be tuned. The calibration process is often iterative and requires a combination of expert knowledge and computational tools. The optimization algorithm iteratively chooses new parameter values to evaluate, and the model is run with these values to generate outputs. The outputs are compared to observed data, and a loss function is calculated to quantify the difference between the model outputs and the observed data. The optimization algorithm then uses this loss function to update its search strategy and choose new parameter values to evaluate. This process continues until the algorithm converges to a set of parameter values that minimize the loss function.\n",
    "\n",
    "While many optimization algorithms are available, Starsim has a built-in interface to the Optuna library, which we will demonstrate in this tutorial. We will use a simple Susceptible-Infected-Recovered (SIR) model as an example. We will tune three input parameters, the infectivity parameter, `beta`, the initial prevalence parameter, `init_prev`, and the Poisson-distributed degree distribution parameter, `n_contacts`. We will calibrate the model using a beta-binomial likelihood function so as to match prevalence at three distinct time points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with a few imports and default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports and settings\n",
    "import sciris as sc\n",
    "import starsim as ss\n",
    "import pandas as pd\n",
    "\n",
    "debug = False # If true, will run in serial\n",
    "do_plot = 1\n",
    "do_save = 0\n",
    "n_agents = 2e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibration class will require a base `Sim` object. This `sim` will later be modified according to parameters selected by the optimization engine. The following function creates the base `Sim` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sim():\n",
    "    \"\"\" Helper function to create the base simulation object \"\"\"\n",
    "    sir = ss.SIR(\n",
    "        beta = ss.beta(0.075),\n",
    "        init_prev = ss.bernoulli(0.02),\n",
    "    )\n",
    "    random = ss.RandomNet(n_contacts=ss.poisson(4))\n",
    "\n",
    "    sim = ss.Sim(\n",
    "        n_agents = n_agents,\n",
    "        start = sc.date('1990-01-01'),\n",
    "        dur = 40,\n",
    "        dt = 1,\n",
    "        unit = 'day',\n",
    "        diseases = sir,\n",
    "        networks = random,\n",
    "    )\n",
    "\n",
    "    # Remember to return the sim object\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the calibration parameters. These are the inputs that Optuna will be able to modify. Here, we define three such parameters, `beta`, `init_prev`, and `n_contacts`.\n",
    "\n",
    "Each parameter entry should have range defined by `low` and `high` as well as a `guess` values. The `guess` value is not used by Optuna, rather only for a check after calibration completes to see if the new parameters are better than the `guess` values.\n",
    "\n",
    "You'll notice there are a few other parameters that can be specified. For example, the data type of the parameter appears in `suggest_type`. Possible values are listed in the Optuna documentation, and include suggest_float (https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.suggest_float) for float values and suggest_int (https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.suggest_int) for integer types.\n",
    "\n",
    "To make things easier for the search algorithm, it's helpful to indicate how outputs are expected to change with inputs. For example, increasing `beta` from 0.01 to 0.02 should double disease transmission, but increasing from 0.11 to 0.12 will have a small effect. Thus, we indicate that this parameter should be calibrated with `log=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the calibration parameters\n",
    "calib_pars = dict(\n",
    "    beta = dict(low=0.01, high=0.30, guess=0.15, suggest_type='suggest_float', log=True), # Note the log scale\n",
    "    init_prev = dict(low=0.01, high=0.05, guess=0.15), # Default type is suggest_float, no need to re-specify\n",
    "    n_contacts = dict(low=2, high=10, guess=3, suggest_type='suggest_int'), # Suggest int just for this demo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization engine iteratively chooses input parameters to simulate. Those parameters are passed into the following `build_sim` function as a dictionary of `calib_pars` along with the base `sim` and any other key word arguments.\n",
    "\n",
    "When modifying a `sim`, it is important to realize that the simulation has not been initialized yet. Nonetheless, the configuration is available for modification at `sim.pars`, as demonstrated in the function below for the SIR example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sim(sim, calib_pars, **kwargs):\n",
    "    \"\"\" Modify the base simulation by applying calib_pars \"\"\"\n",
    "\n",
    "    sir = sim.pars.diseases # There is only one disease in this simulation and it is a SIR\n",
    "    net = sim.pars.networks # There is only one network in this simulation and it is a RandomNet\n",
    "\n",
    "    for k, pars in calib_pars.items(): # Loop over the calibration parameters\n",
    "        if k == 'rand_seed':\n",
    "            sim.pars.rand_seed = v\n",
    "            continue\n",
    "\n",
    "        # Each item in calib_pars is a dictionary with keys like 'low', 'high',\n",
    "        # 'guess', 'suggest_type', and importantly 'value'. The 'value' key is\n",
    "        # the one we want to use as that's the one selected by the algorithm\n",
    "        v = pars['value']\n",
    "        if k == 'beta':\n",
    "            sir.pars.beta = ss.beta(v)\n",
    "        elif k == 'init_prev':\n",
    "            sir.pars.init_prev = ss.bernoulli(v)\n",
    "        elif k == 'n_contacts':\n",
    "            net.pars.n_contacts = ss.poisson(v)\n",
    "        else:\n",
    "            raise NotImplementedError(f'Parameter {k} not recognized')\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% Define the tests\n",
    "def test_calibration(do_plot=False):\n",
    "    sc.heading('Testing calibration')\n",
    "\n",
    "    # Define the calibration parameters\n",
    "    calib_pars = dict(\n",
    "        beta = dict(low=0.01, high=0.30, guess=0.15, suggest_type='suggest_float', log=True), # Log scale and no \"path\", will be handled by build_sim (ablve)\n",
    "        init_prev = dict(low=0.01, high=0.05, guess=0.15, path=('diseases', 'hiv', 'init_prev')), # Default type is suggest_float, no need to re-specify\n",
    "        n_contacts = dict(low=2, high=10, guess=3, suggest_type='suggest_int', path=('networks', 'randomnet', 'n_contacts')), # Suggest int just for demo\n",
    "    )\n",
    "\n",
    "    # Make the sim and data\n",
    "    sim = make_sim()\n",
    "\n",
    "    '''\n",
    "    prevalence = ss.CalibComponent(\n",
    "        name = 'hiv.prevalence',\n",
    "\n",
    "        # By default, automate these based on name\n",
    "        real_data = data['hiv.prevalence'],\n",
    "        sim_data_fn = lambda sim: pd.Series(sim.results.hiv.prevalence, index=sim.results.hiv.timevec),\n",
    "\n",
    "        conform = ss.eConform.PREVALENT,\n",
    "        likelihood = ss.eLikelihood.POISSON,\n",
    "\n",
    "        weight = 1,\n",
    "    )\n",
    "    '''\n",
    "\n",
    "    infectious = ss.CalibComponent(\n",
    "        name = 'Infectious',\n",
    "\n",
    "        # \"real_data\" actually from a simulation with pars\n",
    "        #   beta=0.075, init_prev=0.02, n_contacts=4\n",
    "        real_data = pd.DataFrame({\n",
    "            'n': [200, 197, 195], # Number of individuals sampled\n",
    "            'x': [30, 30, 10],    # Number of individuals found to be infectious\n",
    "        }, index=pd.Index([ss.date(d) for d in ['1990-01-12', '1990-01-25', '1990-02-02']], name='t')), # On these dates\n",
    "        \n",
    "        sim_data_fn = lambda sim: pd.DataFrame({\n",
    "            'n': sim.results.n_alive,\n",
    "            'x': sim.results.sir.n_infected,\n",
    "        }, index=pd.Index(sim.results.timevec, name='t')),\n",
    "\n",
    "        conform = ss.eConform.PREVALENT,\n",
    "        nll_fn = ss.eLikelihood.BETA_BINOMIAL,\n",
    "\n",
    "        weight = 1,\n",
    "    )\n",
    "\n",
    "    # Make the calibration\n",
    "    calib = ss.Calibration(\n",
    "        calib_pars = calib_pars,\n",
    "        sim = sim,\n",
    "\n",
    "        build_fn = build_sim, # Use default builder, Calibration.translate_pars\n",
    "        build_kwargs = None,\n",
    "\n",
    "        components = [infectious],\n",
    "\n",
    "        total_trials = 1_000,\n",
    "        n_workers = None, # None indicates to use all available CPUs\n",
    "        die = True,\n",
    "        debug = debug,\n",
    "    )\n",
    "\n",
    "    # Perform the calibration\n",
    "    sc.printcyan('\\nPeforming calibration...')\n",
    "    calib.calibrate(confirm_fit=False)\n",
    "\n",
    "    # Confirm\n",
    "    sc.printcyan('\\nConfirming fit...')\n",
    "    calib.confirm_fit()\n",
    "    print(f'Fit with original pars: {calib.before_fits}')\n",
    "    print(f'Fit with best-fit pars: {calib.after_fits}')\n",
    "    if calib.after_fits.mean() <= calib.before_fits.mean():\n",
    "        print('✓ Calibration improved fit')\n",
    "    else:\n",
    "        print('✗ Calibration did not improve fit, but this sometimes happens stochastically and is not necessarily an error')\n",
    "\n",
    "    if do_plot:\n",
    "        calib.plot_sims()\n",
    "        calib.plot_trend()\n",
    "\n",
    "    return sim, calib\n",
    "\n",
    "\n",
    "#%% Run as a script\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Useful for generating fake \"real_data\"\n",
    "    if False:\n",
    "        sim = make_sim()\n",
    "        pars = {\n",
    "            'beta'      : dict(value=0.075),\n",
    "            'init_prev' : dict(value=0.02),\n",
    "            'n_contacts': dict(value=4),\n",
    "        }\n",
    "        sim = build_sim(sim, pars)\n",
    "        ms = ss.MultiSim(sim, n_runs=25)\n",
    "        ms.run().plot()\n",
    "\n",
    "    T = sc.timer()\n",
    "    do_plot = True\n",
    "\n",
    "    sim, calib = test_calibration(do_plot=do_plot)\n",
    "\n",
    "    T.toc()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
